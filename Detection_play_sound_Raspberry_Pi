import cv2
from playsound import playsound
import time
import numpy as np

def detect_motion(frame, background):
    # Convert frame to grayscale and blur it
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (21, 21), 0)
    
    # Compute difference between current frame and background
    delta_frame = cv2.absdiff(background, gray)
    thresh = cv2.threshold(delta_frame, 30, 255, cv2.THRESH_BINARY)[1]
    thresh = cv2.dilate(thresh, None, iterations=2)
    
    # Find contours (motion areas)
    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for contour in contours:
        if cv2.contourArea(contour) > 500:  # Minimum area to count as motion
            return True
    return False

def and_gate(input1, input2):
    return input1 and input2

def detection_system():
    print("Detection System Starting...")

    # Initialize two USB cameras
    cap1 = cv2.VideoCapture(0)  # First USB camera
    cap2 = cv2.VideoCapture(1)  # Second USB camera

    if not cap1.isOpened() or not cap2.isOpened():
        print("Error: Could not open one or both cameras.")
        return

    # Set resolution (optional, adjust as needed)
    cap1.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap2.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    # Capture initial background frames
    ret1, background1 = cap1.read()
    ret2, background2 = cap2.read()
    if not ret1 or not ret2:
        print("Error: Could not read from cameras.")
        cap1.release()
        cap2.release()
        return

    background1 = cv2.cvtColor(background1, cv2.COLOR_BGR2GRAY)
    background2 = cv2.cvtColor(background2, cv2.COLOR_BGR2GRAY)

    try:
        while True:
            # Read frames from both cameras
            ret1, frame1 = cap1.read()
            ret2, frame2 = cap2.read()
            if not ret1 or not ret2:
                print("Error: Failed to capture frames.")
                break

            # Detect motion in each camera
            sensor1 = detect_motion(frame1, background1)
            sensor2 = detect_motion(frame2, background2)

            # AND gate logic
            if and_gate(sensor1, sensor2):
                print("Motion detected in both cameras! Playing 'Sail' by AWOLNATION...")
                song_path = r'/home/pi/Music/Sail.mp3'
                try:
                    playsound(song_path)
                except Exception as e:
                    print(f"Error playing 'Sail': {e}")
            else:
                print("No simultaneous detection.")

            # Show camera feeds (optional, for debugging)
            cv2.imshow('Camera 1', frame1)
            cv2.imshow('Camera 2', frame2)

            # Exit on 'q' key press
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

            time.sleep(0.1)  # Reduce CPU usage

    except KeyboardInterrupt:
        print("Stopped by user.")

    finally:
        # Release resources
        cap1.release()
        cap2.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    detection_system()
